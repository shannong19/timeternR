---
documentclass: jss
author:
  - name: Shannon K. Gallagher
    affiliation: |
      | Biostatistics Research Branch
      | National Institute of Allergy 
      | and Infectious Diseases
    # use this syntax to add text on several lines
    address: |
      | 5603 Fishers Lane
      | Rockville, MD 20852
    email: \email{shannon.gallagher@nih.gov}
    url: http://skgallagher.github.io
  - name: Benjamin LeRoy
    affiliation: |
      | Dept. of Statistics & Data Science
      | Carnegie Mellon University
    address: |
      | 5000 Forbes Ave.
      | Pittsburgh, PA 15213
    email: \email{bpleroy@andrew.cmu.edu}
    url:  https://benjaminleroy.github.io/

title:
  formatted: "Time invariant analysis of epidemics with \\pkg{EpiCompare}"
  # If you use tex in the formatted title, also supply version without
  plain:     "Time invariant analysis of epidemics with EpiCompare"
  # For running headers, if needed
  short:     "\\pkg{EpiCompare}"
abstract: >
  We present \pkg{EpiCompare}, an \proglang{R} package that suppliments and enhances current infectious disease analysis pipelines and encourages comparisons across models and epidemics. A major contribution of this work is the set of novel \textit{time-invariate} tools for model and epidemic comparisons - including time-invariate prediction bands. \pkg{EpiCompare} embraces \proglang{R}'s \textit{tidy} coding style to make adoption of the package easier and analysis faster. This paper provides an overview of both the tools in and intuition behind \pkg{EpiCompare} and a thorough demonstrating of the tools through a detailed example of a full data analysis pipeline.
keywords:
  # at least one keyword must be supplied
  formatted: [keywords, not capitalized, "\\proglang{Java}"]
  plain:     [keywords, not capitalized, Java]
preamble: >
  \usepackage{amsmath}
  \usepackage{amsthm}
  \usepackage{afterpage}
  \usepackage[normalem]{ulem} 
output: 
  rticles::jss_article:
    number_sections: TRUE     #added argument option 
    citation_package: "natbib"  #All my citations use biblatex, not natbib. 
classoption: shortnames
biblio-style: jss      #Listed to use in JSS Instructions for Authors, but not in template by default. 
bibliography: EpiCompare.bib  #Also not included in template by default. 
header-includes:
  - \usepackage{booktabs}
  - \usepackage{longtable}
  - \usepackage{array}
  - \usepackage{multirow}
  - \usepackage{wrapfig}
  - \usepackage{float}
  - \usepackage{xcolor}
  - \usepackage{rotating}
---




```{r, setup, include=FALSE}
options(prompt = 'R> ', continue = '+ ')
options(kableExtra.latex.load_packages = FALSE)


knitr::opts_chunk$set(fig.width=12, fig.height=8, fig.path='Figs/',
                      fig.align = "center",
                      echo=TRUE, warning=FALSE, message=FALSE,
                      fig.pos = "H",
                      cache = TRUE)

devtools::load_all("../../")

```

\newcommand{\shannon}[1]{\textcolor{orange}{#1}}
\newcommand{\ben}[1]{\textcolor{violet}{#1}}

\newtheorem{theorem}{Theorem}


# Introduction {short-title="Intro" #sec:intro}

\ben{[Ben says: I something wory about including a full paragraph of introduction before we emphasis where and why we think this tool is useful. Especially the first "where" it could be useful, as I'm not sure how it connets to the more "global" view of the epidemic research area.]}

The recent (and on-going) COVID-19 global pandemic has galvanized public interest in understanding more about infectious disease modeling and has highlighted the usefulness of research in the area of infectious disease epidemiology. Infectious diseases inflict enormous burdens on the world: millions of lives lost and trillions of dollars spent yearly. Infectious disease models typically attempt to do one or more of the following: 1) predict the spread of current and future epidemics \citep[e.g. flu prediction][]{Biggerstaff2016}, 2) analyze past and current epidemics to increase scientific knowledge \citep[e.g. historical measle outbreaks][]{Neal2004}, and 3) forecast or project epidemic scenarios under pre-specified parameters \citep[e.g.][]{ferguson2020}. At the same time, descriptive statistics and visualizations from universities, many branches and levels of government, and news organizations  are an important first step of the process \citep{dong2020,cdc-covid-tracker2021,wp-covid-tracker2021}. \ben{[Ben says: probably should have a conclusion sentence here - seems to end abruptly.]}

With the many visualization and exploratory tools, models and modeling paradigms, and reviews and comparisons in the literature and through the MIDAS (Models of Infectious Disease Agent Study) network \citep{midasnetwork2021}, this field has a lot of devices to aid an individual practitioner decide the correct approach.  For example, \proglang{R} packages such as \pkg{surveillance}, \pkg{EpiModel}, and \pkg{pomp} have all made significant steps in standardizing the flow of the data analysis pipeline for epidemic modeling through digitizing data sets, making accessible statistical models, and providing a plethora of educational material for both coding novices and experts alike \citep{surveillance2017,Jenness2018,King2016}.

At the same time, analysis packages often only address a specific portion of the analysis pipeline\ben{\sout{, for instance focusing on certain types of models.}} \ben{These m}odeling tools\ben{\sout{, which}} usually require learning package-specific syntax\ben{\sout{,}} and often don't provide easy ways to compare and assess their models on new data. Moreover, exploring\ben{, \sout{and}} modeling \ben{and comparing} epidemics require transforming and \textit{tidying} data in different ways. To fill these gaps, we present our \proglang{R} package \pkg{EpiCompare}. Our package's primary focus is to aid and advance research in the area of comparison and assessment of epidemic and epidemiological models. In Figure \ref{fig:pipeline}, we illustrate the data analysis pipeline of infectious diseases  as 1) data pre-processing, 2) exploratory data analysis (EDA), 3) modeling and simulating, 4) post-processing, and 5) comparison and assessment; where each previous part of the pipeline influences the next. \pkg{EpiCompare} provides tools to aids practitioners in all areas of this pipeline.


<!-- # old draft
The recent (and currently on-going) COVID-19 global pandemic has galvanized public interest in understanding more about infectious disease modeling and has highlighted the usefulness of research in the area of infectious disease epidemiology. Infectious disease models typically attempt to do one or more of the following: 1) predict the spread of current and future epidemics \citep[e.g. flue prediction][]{Biggerstaff2016}, 2) analyze past and current epidemics to increase scientific knowledge \citep[e.g. historical measle outbreaks][]{Neal2004}, and 3) forecast or project epidemic scenarios under pre-specified parameters \citep[e.g. ...][]{}. The COVID-19 pandemic highlights how all three goals are important both separately and taken as a whole.  Infectious diseases inflict enormous burdens on the world: millions of lives lost and trillions of dollars spent yearly.  Correctly analyzing and addressing these issues aids in prevention and mitigation of future outbreaks. \shannon{really like this paragraph}


The current epidemic of COVID-19 also highlights that infectious disease  models are only one piece of the overall analysis pipeline. University based resources like John Hopkins' and government numerical dashboards (across all levels of government) during the COVID-19 epidemic remind us that descriptive statistics and visualization can be a important first step in the process (multiple \cite{}?).} \shannon{add comment about NYT or something} Still, rightly so, a large amount of theoretical work goes into modeling epidemics, with different models focusing at the individual / agent level, network structure or just aggregate flows (review paper \cite{}?). All placing individuals / proportions of the populations into different states (e.g. suspectible, exposed, infected, recovered, etc.). With all these models, review and comparison papers in the literature and through MIDAS (Models of Infectious Disease Agent Study) Control Center helps the individual practitioner decide the correct approach. \shannon{along with expertise from healthcare professionals...}

At the same time, analysis packages often only address a portion of the analysis pipeline. Modeling tools often don't provide easy ways to compare and assess their models on new data. Moreover, exploring and modeling epidemics require transforming and \textit{tidying} data in different ways. To fill these gaps, we present our our \proglang{R} package \pkg{EpiCompare}. Our package's primary focus is to aid and advance research in the area of comparison and assessment of epidemic \& epidemiological models. In Figure \ref{fig:pipeline}, we illustrate the data analysis pipeline of infectious diseases  as 1) data pre-processing, 2) exploratory data analysis (EDA), 3) modeling and simulating, 4) post-processing, and 5) comparison and assessment; where each previous part of the pipeline influences the next. \pkg{EpiCompare} provides tools to aids practitioners in all areas of this pipeline. 
-->

\begin{figure}[!ht]
    \centering
    \includegraphics[width = 1\textwidth]{images/pipeline1.png}
    \caption{An idealized epidemiological data analysis pipeline.}
    \label{fig:pipeline}
\end{figure}

\pkg{EpiCompare} also emphasizes the value of analyzing epidemics in a \textit{time-invariant} way. Epidemics, despite by definition being a process that evolves over time, often need to be compared in a way not constrained to initial times or time scales to understand the processes at play. 
<!-- Additionally, many tools designed to examine the quantity of the population in each epidemic state (for example: quantity of Susceptible vs Infectious vs Recovered individuals) don't always as intelligently capture the natural connections between the proportion of individuals in these states. \shannon{I don't quite understand this.  Is this because of underreporting?  If so I'm not sure how EpiCompare helps us here.} -->
\ben{Time-invariant analysis can also make it easier to compare state-space models in a more global, holistic fashion. \sout{Moreover, m} M}any current \ben{time-dependent} comparison tools for state-space models (e.g. SIR models) \ben{\sout{highlight} examine} the proportion of individuals in each state (at a given time) in a piece-wise / marginal  fashion. \ben{These \sout{This}} approach\ben{es} may reduce the amount of connections that can be seen, similar to projections of a multidimensional distribution onto a single axis at a time. Tools in \pkg{EpiCompare} give the user the ability to extend their toolkit to evaluate epidemics within a time-invariant lens. The goal of \pkg{EpiCompare} is not to supplant existing infectious disease modeling tools and software but, rather, is a concerted effort to create standard and fair comparisons among models developed for disease outbreaks and outbreak data.

This paper is broken up into the following sections; section \ref{sec:time-invariant} motivates and showcases tools of time-invariant analysis,  section \ref{sec:overview} presents an outline of how \pkg{EpiCompare} aids a practitioner in every step of the pipeline and section \ref{sec:tour} provides a \ben{\sout{thorough}} demonstrating of the tools through a detailed example of a full data analysis pipeline.


# Motivation and tools for time-invariant analysis {short-title="Time-invariant" #sec:time-invariant}

\shannon{time invariance vs. time invariant analysis??}

\shannon{I again changed this section a lot, but hopefully it's more in line with what you are thinking.  The story I want to tell is 1) introduce the concept of time invariance; 2) demonstrate time invariance through R0 and tell why it is important; 3) visualize R0 from the SIR model with a time-invariant plot\footnote{\ben{[Ben says: defend how this fits into the narrative?]}} and 4) talk }\ben{Time invariance in} \sout{about}\shannon{ models beyond SIR.}

\shannon{I noticed the ternary plot kinda fell out of this section and it's not really detailed anywhere else in the paper.  So I put it back in.  It's a non-standard plot and a feature of EpiCompare so I think it's worth talking about, and I think it's appropriate to introduce in this section.}

<!--Epidemics can be difficult to compare to one another due to differences in diseases, locations, or population behaviors, or times.  In \pkg{EpiCompare}, we emphasize comparisons between epidemics adjusting for the last component, time.  Time-invariant analysis is beneficial because by adjusting for the unit of infection rate, we can focus on the "lifetime" of an epidemic, a view that is concerned more with the number of lives affected than as opposed to any specific time constraint.    Time-invariant analysis is also beneficial when there are gaps in time between occurrences of outbreaks of a similar nature in different geographic regions.  Finally, time-invariant analysis is beneficial because many studies talk about a period of ``exponential growth'' of the number of outbreaks \citep{chowell2007,wallinga2007generation,forsberg2008}.

Time-invariant analysis, as it appears in \pkg{EpiCompare} solves the above issues by observing functionals which attempt to capture the general shape of the epidemic with respect to the proportion of the population in each epidemic state.  This allows us to compare scenarios as different as, for instance as a decades-long outbreak HIV in the US compared to a 10 day outbreak of norovirus on a cruise ship.  Moreover, this tool avoids the need for choosing a 'beginning' $t_0$ or 'end' $t_F$ of an epidemic, choices \cite{gallagher2020} show that can heavily influence, for example,  estimates of peak infection height or the reproduction number $R_0$.
-->

\pkg{EpiCompare} delivers \textit{time-invariance} centric analysis by (1) taking a global, not marginal view of how epidemics move through populations and (2) by treating full epidemics as filaments^[\ben{[Ben says: Do we need a footnote explaining what this is more clearly?]}] and not points produced by functions of time. The following section aims to highlight the strengths of \textit{time-invariance} and define the mathematical foundations that \pkg{EpiCompare}’s tools stand upon.

Mathematically, epidemics are complex objects.  They are hard to assess and compare to one another due to the differences in the diseases, the location where the outbreak occurs,  how the affected population reacts, and the time \ben{related} features (including start of the epidemic, speed of infection and more). Time-invariant analysis make different epidemics easier to compare by removing many time dependent aspects of an epidemic. Instead it focuses on the overall trajectory of an epidemic, emphasizing the number of lives affected. \shannon{[Shannon says: really like the lives affected part; I think that's a powerful statement.]}

## Motivating time-invariance through $R_0$ {short-title="motivating through R0" #r0}

Time-invariance analysis, as it appears in \pkg{EpiCompare}, \sout{can be seen as an attempt to escape} \shannon{bypasses}  many difficulties \shannon{in} comparing different epidemics. With time-invariant analysis, comparing the decades-long outbreak of HIV in the US to a 10 day outbreak of norovirus on a cruise ship is \sout{still} possible. Time-dependent problems can arise when estimation of certain epidemiological parameters, including the reproductive number $R_0$, which \citet{Gallagher2020} show can be \sout{heavily impacted} \shannon{strongly effected} by choices of beginning and ending time points of an epidemic. 

\ben{
Story: 
(1) basic definition of $R_0$, (2) emphasis that $R_0$ captures a lot of information about an epidemic. Given 3 number example and discuss how one would usually interpret what the differences in $R_0$ meant (3) maybe connect to \# of $R_0$ estimates for COVID-19 (Aronson et al 2020). 
}

$R_0$ is probably the most famous time-invariant numerical summary of an epidemic and is \shannon{often} associated with the Susceptible-Infectious-Recovered (SIR) model \citep{hethcote2001}. For a demonstration of $R_0$ getting lost in a time-dependent analysis we introduce the \citet{Kermack1927}’s common SIR model. This model captures the transitions from one state to the next as a system of ordinary differential equations, where $N$ is the total number of individuals, $\beta$ is the rate of infection, and $\gamma$ is the rate of recovery,

\begin{align}\label{eq:sir-ode}
    S^\prime(t) &= -\frac{\beta S(t)I(t)}{N} \\
    I^\prime(t) &= \frac{\beta S(t)I(t)}{N} - \gamma I(t) \nonumber\\
    R^\prime(t) &= \gamma I(t) \nonumber.
\end{align}

From this model, $R_0 = \beta/\gamma$, aka the ratio of the estimated infection rate compared to the estimated recovery rate.  Since $\beta$ and $\gamma$ are both rates (of infection and recovery, respectively), the ratio of the two, $R_0$, is a time-invariant quantity.  \shannon{Once $R_0$ is estimated, then important epidemic quantities can be inferred such as a the percent of a population needed to be vacccinated to stop the sustained spread of an epidemic and the total number of infections, the final size.  Moreover, $R_0$ allows us to compare different disease outbreaks and different outbreaks on the same scale.  }

## Visualizing $R_0$ {short-title="visualizing r0" #vis-r0}

With regards to traditional epidemic $state$ vs. $time$ plots, when \sout{comparing}\shannon{examining} different epidemics their $R_0$s are often impossible to compare. This can be seen in a basic example, where we have two different epidemics that start in two populations of 1000 people with 10 individuals \shannon{initially} infected, but with \sout{different parameters} \shannon{different infection and recovery rates (see Eq. \ref{eq:sir-ODE}}). Specifically suppose that $\beta_1, \gamma_1 = (a,b)$ and $\beta_2, \gamma_2 = (ca,cb)$ where $a, b, c > 0$. Further suppose we observe both of these epidemics for 15 days. The epidemic trajectories are shown in the $state$ vs. time plots in Figure \ref{fig:different-scales-standard}.  At a glance, we may \sout{assume} \shannon{believe} that Model 1 has a larger $R_0$ than Model 2 because the peak of infection occurs more quickly than in Model 2.  On the other hand, we may \sout{think} \shannon{believe} Model 2 has a larger $R_0$ because we may think the number of infections in that model has not yet peaked at time 15. Yet, both epidemics have the same $R_0$ of 2.

\shannon{Introduce ternary plots here.  The below paragraphs are mostly new}

However, time-invariant centric analysis allows us to visualize $R_0$ for the Kermack and McKendrick SIR model.  We call the epidemic trajectory of number of individuals in each state a \textit{filament}.  Mathematically, a filament $\psi$ for the SIR model  $\psi$ this is the set of points of the number in each state for each time point,
$$
\psi = \left \{(S(t), I(t), R(t)): S, I, R \ge 0, S + I + R = N \right \}_{t=0:T}.
$$

Since the number in each state is non-negative and the sum over the three states for a given time point sums to $N$, then $\psi$ will lay in a 2d triangular plane, i.e. a ternary plot.  As a result, we can visualize the global trajectory of an epidemic in a single 2d plot and ultimately $R_0$.  \shannon{Show pic here?}

We visualize the two epidemics in a global, ternary view in Figure \ref{fig:different-scales-tern}.  Without getting into too much detail of the intricacies of this plot, we immediately see the points of the two filaments $\psi$ seem to form the same trajectory.  Now, it is much clearer that Model 2 is following the same trajectory as Model 1 but is not as far along in the infection process.  We can see there is something fundamentally linking these two different epidemics, and this fundamental link turns out to be $R_0$.

We can show this mathematically if we let our two epidemics be presented as $\{(S_1(t), I_1(t), R_1(t))\}_{t\geq0}$, $\{(S_2(s), I_2(s), R_2(s))\}_{s \geq 0}$ respectively.  As with the example, assume both models have the same initial values $(S(0), I(0), R(0))$, and let $R_0 =\frac{\beta_1}{\gamma_1} = \frac{\beta_2}{\gamma_2}$ where $\beta_i$ and $\gamma_i$ are the average infection rate and recovery rate, respectively, for SIR model $i=1, 2$. And define $a>0$ to be the relative scalar such that $\beta_2 = a \beta_1$ if and only if $\gamma_2 = a \gamma_1$.

\begin{theorem}\label{thm:sir-scale}
Let there be two SIR models as described above.  Then for all $t > 0$ there exists an $s>0$ such that $(S_1(t), I_1(t), R_1(t)) = (S_2(s), I_2(s), R_2(s))$.  Moreover, $s = \frac{1}{a}t$.
\end{theorem}

The proof of Theorem \ref{thm:sir-scale} relies on a fairly recent result from \cite{Harko2014} and is shown in detail in Proof \ref{proof:thm}.  The consequence of Theorem \ref{thm:sir-scale} is that for two SIR models that have the same initial percent of individuals in each state and $R_0$ then for every point on the epidemic path of the first SIR model is also a point on the epidemic path of the second SIR model.



<!-- ## $R_0$  and time-invariant analysis {short-title="r0" #r0}

 By definition, $R_0$ is the number of expected secondary infections when a primary infection is introduced to a susceptible population.  $R_0$ is also, maybe, the most famous \textit{time-invariant} numerical summary of an epidemic, which allows epidemics to be compared to one another in both different time and geographic scales. For example, $R_0$ for Covid-19 is estimated to be between 2-3, seasonal influenza between 1.2-2, and modern measles outbreaks as large as 12 \citep{midas2020,biggerstaff2014,namee2018}.

Estimators for $R_0$ are dependent on the epidemic modeling framework, which consists of which states an individual can occupy (e.g. susceptible, infectious, recovered) and a description of how individuals move from one state to the next over time (see \cite{hethcote1994}).  A common epidemic modeling framework is the SIR model, originally introduced by @kermack1927.  Transitions from one state to the next are defined by a series of ordinary differential equations, where $N$ is the (fixed) total number individuals, $\beta$ is the rate of infection, and $\gamma$ is rate of recovery, 
\begin{align}\label{eq:sir-ode}
      S^\prime(t) &= -\frac{\beta S(t)I(t)}{N} \\
      I^\prime(t) &= \frac{\beta S(t)I(t)}{N} - \gamma I(t) \nonumber\\
      R^\prime(t) &= \gamma I(t) \nonumber.
  \end{align}
From this, $\hat{R}_0 = \frac{\hat{\beta}}{\hat{\gamma}}$, the ratio of the estimated infection rate compared to the estimated recovery rate.


With regards to traditional epidemic $state$ vs. $time$ plots, $R_0$ is difficult to visualize, especially with respect from one epidemic to another. For example, consider the scenarios where the first epidemic is generated from a SIR model with $(S(0) = 990, I(0) = 10)$, $\beta_1 = 0.3$ and $\gamma_1 = 0.15$, and the second epidemic is generated from a SIR model with $(S(0) = 990, I(0) = 10)$, $\beta_2 = 0.24$ and $\gamma_1 = 0.12$ over the first 15 days.  Both epidemics have the same value of $R_0 = \beta_1/ \gamma_1 = \beta_2 / \gamma_2 = 2$.  The epidemic trajectories are shown in the $state$ vs. time plots in Figure \ref{fig:different-scales-standard}.  At a glance, we may assume that Model 1 has a larger $R_0$ than Model 2 because the peak of infection occurs more quickly than in Model 2.  On the other hand, we may think Model 2 has a larger $R_0$ because we may think the number of infections in that model has not yet peaked at time 15. -->


```{r echo = FALSE}
devtools::load_all()
library(tidyr)
library(dplyr)
library(knitr)
library(kableExtra)
library(ggplot2)
set.seed(1)

theme_set(theme_bw(base_size = 24))
```


```{r echo = FALSE, fig.cap = "\\label{fig:different-scales-standard}Example of two epidemics with different $\\beta$ and $\\gamma$ paremeters but the same initial reproduction number $R_0$ = 2.  Both plots are generated from models with $N= 1000$ individuals with $S(0) = 990$ and $I(0) = 10$."  }
set.seed(1225)
theme_set(theme_bw(base_size = 24))

beta1 <- .8
gamma1 <- .4
scale <- .8
sir1 <- simulate_SIR_agents(n_sims = 100, n_time_steps = 40,
                            beta = beta1, gamma = gamma1,
                            init_SIR = c(990, 10, 0)) %>%
  group_by(sim) %>%
  agents_to_aggregate(states = c(tI, tR)) %>%
  group_by(t) %>%
  summarize(S = mean(X0), I = mean(X1), R = mean(X2),
            .groups = "drop") %>%
  mutate(type = "Model 1")

sir2 <- simulate_SIR_agents(n_sims = 100, n_time_steps = 40,
                            beta = beta1 * scale, gamma = gamma1 * scale,
                            init_SIR = c(990, 10, 0)) %>%
  group_by(sim) %>%
    agents_to_aggregate(states = c(tI, tR)) %>%
  group_by(t) %>%
  summarize(S = mean(X0), I = mean(X1), R = mean(X2),
            .groups = "drop") %>%
  mutate(type = "Model 2")

df <- bind_rows(sir1, sir2)

df_long <- df %>%
         tidyr::pivot_longer(cols = c(S, I, R))  %>%
  mutate(name = factor(name, levels = c("S", "I", "R"))) %>%
  filter(t <= 15)

ggplot(data = df_long,
       aes(x = t, y = value, col = type)) + 
  facet_wrap(~name, ncol = 1, scales = "free") +
  geom_line() +
  geom_point() +
  scale_color_manual(values = c("red", "blue"), name = "Epidemic") +
  labs(x = "Time",
       y = "# in state",
       title = latex2exp::TeX("Comparing two epidemics over first 15 days with same $R_0$")) +
  coord_cartesian(xlim = c(0, 15))
```

<!--
However, when we plot the trajectories as a single curve using the ternary plot in the time-invariant view, we immediately see a different story.  In this time-invariant view in Fig. \ref{fig:different-scales-tern}, the points seem to overlap and form the same trajectory.  Now it seems to be that Model 2 is following the same trajectory as Model 1 but is not as far along in the infection process.  We can see there is something fundamentally linking these two different epidemics, and this fundamental link turns out to be $R_0$.

More formally, let two Kermack and McKendrick  SIR models(see Eq.\eqref{eq:sir-ode} )  be denoted $(S_1(t), I_1(t), R_1(t))$ and $(S_2(t), I_2(t), R_2(t))$, respectively, for $t > 0$. Assume both models have initial values $(S(0), I(0), R(0))$.  Let $R_0 = \frac{\beta_1}{\gamma_1} = \frac{\beta_2}{\gamma_2}$ where $\beta_i$ and $\gamma_i$ are the average infection rate and recovery rate, respectively, for SIR model $i=1, 2$.  Equivalently, $\beta_2 = a \beta_1$ if and only if $\gamma_2 = a \gamma_1$ for some $a > 0$. 

\begin{theorem}\label{thm:sir-scale}
Let there be two SIR models as described above.  Then for all $t > 0$ there exists an $s>0$ such that $(S_1(t), I_1(t), R_1(t)) = (S_2(s), I_2(s), R_2(s))$.  Moreover, $s = \frac{1}{a}t$.
\end{theorem}

The proof of Theorem \ref{thm:sir-scale} relies on a fairly recent result from \cite{Harko2014} and is shown in detail in Proof \ref{proof:thm}.  The consequence of Theorem \ref{thm:sir-scale} is that for two SIR models that have the same initial percent of individuals in each state and $R_0$ then for every point on the epidemic path of the first SIR model is also a point on the epidemic path of the second SIR model. Taking the sample simulations from Fig. \ref{fig:different-scales-standard}, Fig. \ref{fig:different-scales-tern} presents these two models in a ternary plot.  This means with our time-invariant ternary plot, that at a glance, we can tell if two epidemics have different values of $R_0$.
-->

```{r warning = FALSE, message = FALSE, echo = FALSE, fig.cap = "\\label{fig:different-scales-tern}Example of two epidemics with different $\\beta$ and $\\gamma$ paremeters but the same initial reproduction number $R_0$ = 2.  Both plots are generated from models with $N= 1000$ individuals with $S(0) = 990$ and $I(0) = 10$.  These are plotted in the time-invariant view, where we can see the number of susceptible, infectious, and recovered."}
ggplot(data = df %>%
         filter(t <= 15)) +
  geom_path(aes(x = S, y = I, z = R,
                     col = type)) +
  geom_point(aes(x = S, y = I, z = R,
                     col = type)) +
    coord_tern() + 
  theme_sir() +
  scale_color_manual(values = c("red", "blue"), name = "Epidemic") 
```





##  Beyond $R_0$ and Kermack’s and McKendrick SIR Models {short-title="Beyond R0 and SIR" #beyond-r0-sir}

Through $R_0$ \shannon{example}, we see that treating epidemics more like a \sout{function of the time points in some higher dimensional space (nicely visualizable with a ternary plot for the SIR models)} \shannon{filaments embedded in a lower dimensional space}, then we can better compare the overall structure of the epidemic and \sout{how it impacted the population} \shannon{see how the population was directly impacted}. \sout{Without knowing the generative structure underlying these two epidemics}, \shannon{When the underlying generative model is unknown for epidemic trajectories}, we propose that time-invariant tools can help compare them in smart ways, and that these ideas can extend past the CITE kermack1927 model and to epidemics with more states. 

\ben{
to be continued - (1) highlight filamental view of the epidemics through their simplex space (2) describe distances that could compare different epidemics with this mindset. Also motivate uncertainty for epidemics now that we have a filamental view (3) emphasis that this idea should extend to higher dimensions (4) present the idea that one could also compare bands together.
}

<!--
## Beyond the Kermack and McKendrick SIR models


Although the result of Theorem \ref{thm:sir-scale} allows for easy visual comparison of $R_0$ in Kermack SIR models, it does require stringent assumptions of homogeneity of behavior in populations.  The use of visualizing epidemics in a time-invariant lens via ternary plots extends beyond those of models that follow the ODEs in the Kermack-McKendrick equations.  Any model with S, I, and R states can be visualized with ternary plots, regardless of birth and death dynamics and regardless of homogeneity of individual behavior.  We can use ternary plots to compare the spread of a disease for groups within a population without time as a confounding factor.  We show an example of this in a later section.




Moreover, time-invariant analysis is also useful for epidemic models with more than three epidemic states. The constraints in three dimensions that are met with the SIR model (there are three epidemic states and for each time step, the sum of total number of individuals in each state is the population size at that time) represents a space of 3d simplices, and the ternary plot specifically represents these simplices, after scaling the values in each state as proportions of the total population at that time (ternary plots are known as a 3d unit simplex due to it's scaling). This same scaling for larger models (i.e. with more states) can be done onto different simplexes. In this package we present tools to help compare models (mostly through simulations).  \pkg{EpiCompare}'s tools permits comparisons of $d$-dimensional objects by projecting them into ($d-1$)-dimensional space.

 Even though higher dimensional models may not be able to visualized simply, we provide a number of tools to aid in the comparison of models and epidemics. The first of which uses multiple simulations under specific model parameters to assess the \shannon{variability?} bairabilty of the model fit. In \pkg{EpiCompare}, we provide ways to create prediction regions for a `true' epidemic under a fully specified model. These regions require representing multi-dimensional structures for functions to completely contain epidemics.  \pkg{EpiCompare} treats these simulations and epidemics as \textit{filamental} objects -- \shannon{need a description for filamental, Ben feel free to change} where not only the outbreak trajectory points are important but also their form which can be considered a function. \shannon{could be useful to have a picture/example here? like  three curves and 2 metrics one where closer under a pointwise distance and the other closer in filamental distance? I'll sketch up an idea unless you have something in your proposal already}
 
 We extend off of papers like \citet{Dalmasso2019a} to create these bands. These high dimensional bands allow the user to assess if the true epidemic is within the band (thereby assessing the model's representation of the epidemic).  With these bands, we can compare \textit{models} to \textit{models} by assessing the distance between the two bands of model representation. We recommend using the Hausdorff distance to compare two bands to one another, as this distance captures how much bigger the sets would have to expand to cover each other.  The Hausdorff distance is defined mathematically as 
\[
d_\text{Hausdorff}(S_1, S_2) = \max \left\{ \sup_{x \in S_1} \inf_{y \in S_2} d(x,y),\; \sup_{y \in S_2} \inf_{x \in S_1} d(x,y)\right\}\;.
\]

-->

# Overview of \pkg{EpiCompare} {short-title="Package overview" #sec:overview}

\afterpage{\clearpage}
\begin{sidewaysfigure}[!ht]
    \centering
    \includegraphics[width = 1\textwidth]{images/pipeline2.pdf}
    \caption{How \pkg{EpiCompare} supplements and aids in the epidemiological data analysis pipeline.}
    \label{fig:pipeline2}
\end{sidewaysfigure}

In this section, we present the tools implemented in \pkg{EpiCompare} and explain how they aid in the  data analysis pipeline.  In Fig. \ref{fig:pipeline2}, we illustrate how our package's functions fit into the data analysis pipeline introduced in Fig. \ref{fig:pipeline}.  All front-facing functions are aimed to be as user-friendly as possible. We also focus on providing the user "tidyverse" style functions, that encourage piping and also follow clear verb naming schemes \citep{Wickham2019}. Although users can typically incorporate \pkg{EpiCompare} into any step in the data analysis process, there are two primary points of entry.  The first point of entry is the very beginning with pre-processing and visualizing raw data, and the second point of entry is after modeling and simulation. Figure \ref{fig:pipeline2} captures these different paths, and we will highlight\footnote{\ben{[Ben says: we need to make sure we actually do highlight ]}} both approaches and how to leverage \pkg{EpiCompare} in the subsections below.


**Data Pre-processing**

The first step of most data analysis is cleaning the data so it can be explored. There are multiple ways to collect epidemiological data. Sometimes individual records are collected, with times of different states of the epidemic (infection, recovery, etc.) as well as individual information like network structure, location, and sub-population information. Other data collections focus on aggregate counts of individuals in each epidemic state.  In fact, usually only the number of new infections at each time step (e.g. weekly case counts) is observed.  Compartment totals (amounts of individuals in each state) are then imputed from those case counts along with other information about the disease and the population of interest.  In \pkg{EpiCompare}, we focus on understanding the overall impact of an outbreak at the aggregate/population level, which allows for examination of overall trends of an epidemic more easily.  

In order to help the practitioner examine epidemics from an aggregate/ population lens, we provide a function called `agents_to_aggregate`. This function transforms data about individual/agents' initial entry into each state (e.g. start of infection, start of recovery, etc.) to an aggregate view of how many individuals were in a state at a given time. There are often situations where grouping agents into subpopulations (e.g. subpopulations defined by age or sex) can highlight different aggregate level trends. For example, research by \citet{rvachev1985,anderson1992,worby2015} develop state-based models that account for subpopulations. In \pkg{EpiCompare}, we facilitate subpopulation analysis by combining \pkg{dplyr}::`group_by` and `agent_to_aggregate` to provide aggregation at a group level.

The `agents_to_aggregate` function is flexible and can deal with a wide range of information about each individual. It can, theoretically, account for infinitely many states.  This functionality allows the practitioner to aggregate information relative to the standard states (e.g. "Susceptible", "Infectious", and "Recovered") as well as add states (e.g. "Exposed", "iMmune", "Hospitalized") (CITE\footnote{\ben{[Ben says: this was originally to back up the claim that SIR is the "standard" states - now we might need to have a paper that says that SIR is the standard states and also suggests other states...]}}). Additionally, `agents_to_aggregate` also permits indicators for death/exit and birth/entry dates. Overall, the function `agents_to_aggregate()` is a powerful tool for pre-processing data.

**EDA**

With raw data, "getting to know" our data currently means figuring out good combinations of visualizations, numerical summaries and subsets. An expert coder has many ways to successfully explore the data in an aggregate lens using `agents_to_aggregate`. \pkg{EpiCompare} also includes tools to rapidly explore data that has three epidemic states. Building on the tools in \pkg{ggplot2} and \pkg{ggtern}, our `geom_aggregate` provides a rapid way to explore different subpopulations' experience of an epidemic by combining the ideas behind `agents_to_aggregate` for three-state models to examine subpopulation trajectories in a 3d simplex space \citep{Wickham2016, Hamilton2018}. \shannon{[Shannon says: come back?]}\footnote{\ben{[Ben says: what does this note mean?]}} Visualization tools for three-state models were developed because (1) SIR models are some of the most common and basic epidemic state-based models and (2) our simplex representation of these epidemics emphasizes a "time-invarance" representation of the data (for a refresher see Section \ref{sec:time-invariant}). \shannon{[Shannon says: make sure SIR is defined before.]}

**Model Fitting and Simulations**


Although this package does not focus on fitting a model to data, we do provide some flexible functions for simulation of basic discrete-time epidemic-state models.  These functions produce individual level information and can be naturally combined with `agents_to_aggregate()` to view these simulations through an aggregate lens.  The function `simulate_SIR_agents()` simulates an SIR epidemic with user inputs for the number of simulations, the initial number in each state, the infection and recovery parameters $(\beta, \gamma$), and the total number of discrete time steps.  This function allows for easy access to SIR model analysis and comparison.  Beyond SIR models, the function `simulate_agents()` takes as input a user-specified transition matrix and other epidemic parameters to allow the user to create simulations of an outbreak for \textit{any} number of states and any number of transitions among them.  This flexibility in states can be used to also reflect group-based dynamics.  This allows for users to explore the space of models in an intuitive way without getting bogged down by too much mathematical detail. For consistency, we have made output from `simulate_agents()` and `simulate_SIR_agents()` compatible with `agents_to_aggregate()` so aggregate information may easily be accessed.


**Post-processing**

Post-processing of modeling and simulation consists of making summary statistics, plots, tables, and other ways to disseminate information to the public.  For example, comma separated value files (`.csv`) are a  standard way to share information within tables.  However, model output is often far more complicated than what a traditional `.csv` would allow.  \shannon{Do we need three sentences about csvs?} As a result, a number of epidemic modeling packages return a special class, specific to their modeling.  The special classes often contain a plethora of information from residuals, model diagnostics, input parameters, and more.  While incredibly useful, these special classes can be difficult for novice coders to navigate. 

To this end, we have adapted a series of `fortify`-style functions, called `fortify_aggregate()` which transform output from packages like \pkg{pomp} and \pkg{EpiModel} into tidy-styled data frames which contain information about the total number of individuals in each state at a given time, for a given simulation.  These fortify functions have output that is consistent with that of `agents_to_aggregate()`.

\shannon{Here Ben talks about filament compression and tidy_dist mats, etc}




**Comparisons and Assessment**

Comparison and assessment of model fit or comparisons of one model to another model can be performed in a variety of ways including mean square error, AIC, plots, and more.  Perhaps the most useful tool \pkg{EpiCompare} has to offer to the expert, for comparison and assessment of models, is in its post-processing tools which create a standard output.  It is then a matter of writing a script or function made for that standard output to assess the results from multiple models in the way the user desires.

However, for those who like more concrete tools, \pkg{EpiCompare} offers functions to compare prediction regions to one another including `geom_prediction_band()` (which plots the region), and `create_{convex_hull,delta_ball}_structure()`(which returns the `R` output for the given structure), and `contained()` (which allows the user to determine if one set of points is contained in a prediction band).  Additionally, we offer ways to determine if model outputs are compatible with one another, that is how extreme one output is to another.  \shannon{Ben says something about distance}


# A tour of \pkg{EpiCompare} {short-title="Tour" #sec:tour}



In this section, we highlight a number of the functionality available in \pkg{EpiCompare}.  These functionality include data cleaning, visualization, simulation, and comparison, in accordance with the data analysis pipeline \ref{fig:pipeline}. We show a full data analysis from beginning to end that can be accomplished in a streamlined and standardized manner.


\subsection{Data and exploratory analysis}

We analyze an outbreak of measles in the town of Hagelloch, Germany from 1861-1862, a data set organized by \cite{pfeilsticker1863}.  The data was later made visible by \cite{oesterle1992} and made available in an \proglang{R} by \cite{surveillance2017}.  The Hagelloch data includes a rich set of features including household members, school level, household locations, date of first symptoms (prodromes), date of measles rash, and even the alleged infector. A subset of the data is shown in Table \ref{tab:hags-people}.   Because of these rich features, this data set has been an ideal testing ground  methodology in infectious disease epidemiology and is used in work by \cite{Neal2004,britton2011,groendyke2012,becker2016}.







```{r hagelloch-subset-view, echo = FALSE}
hagelloch_raw %>% select(PN, HN, NAME, AGE, SEX, CL,  PRO, ERU, IFTO) %>%
  filter(PN %in% paste(c(1:5, 45))) %>% kable(format = "latex", booktabs = TRUE, caption = "Subset of Hagelloch infection data.  Features include the person ID, household ID (HH ID), age, sex, class level (Pre-K/1st/2nd), date of first symptoms, date of the appearance of the measles rash, and the alleged infector ID of the individual.",
                                              linesep = "",
                    col.names = c("ID","HH ID", "Name", "Age", "Sex", 
                                  "Class", "Symp. Start", "Rash Date", "Infector ID"),
                    label = "hags-people") %>%
  kable_styling(position = "center", latex_options = "hold_position")
```

With \pkg{EpiCompare}, we can easily obtain the empirical cumulative incidence function with respect to the measles rash appearance (variable \code{ERU}) with the following tidy-style function, \code{agents_to_aggregate}.  The function \code{agents_to_aggregate} is a key component of \pkg{EpiCompare}, allowing the user to easily switch from an individual-level (i.e. an agent) view of a disease to an aggregate level.  For example, the below code shows how we can convert the agent data to a cumulative incidence of the measles rash, in order to see how the disease spread through the population over time. We can then compare the cumulative incidence of the rash to the cumulative incidence of the prodromes, i.e. the initial symptoms.  We do this with the below code, and a part of the cumulative incidence data output are shown in Table \ref{tab:cif-rash}.  The argument \code{integer_time_expansion} indicates whether we should include all time points in the recorded range of the data or only when there is a change in the incidence.

```{r }
cif_rash  <- hagelloch_raw %>%
  mutate(time_of_rash = as.numeric(ERU - min(PRO, na.rm = TRUE))) %>%
  agents_to_aggregate(states = time_of_rash,
                      integer_time_expansion = FALSE) %>%
  mutate(type = "Rash")
```


```{r echo = FALSE}
cif_rash %>% 
  dplyr::select(-type) %>%
  head(5) %>% kable(booktabs = TRUE,
                               caption = "Turning the individual-level information from the Hagelloch data to an aggregate view of the cumulative incidence of the measles rash in the population over time.",
                               label = "cif-rash",
                              col.names = c("Time", "# Susceptible", "# Total rash appearances") ) %>%
  kable_styling(position = "center", 
                latex_options = "hold_position"
                      )
```


One question of interest is the duration between initial onset of prodromes or symptoms and the appearance of the measles rash.  Since \code{agent_to_aggregate} outputs a tidy-style data frame, it is a simple task to plot the two sets of incidence curves on the same graph (Fig. \ref{fig:cifs}).





```{r}
cif_prodromes <- hagelloch_raw %>%
  mutate(time_of_PRO = as.numeric(PRO - min(PRO, na.rm = TRUE))) %>%
  agents_to_aggregate(states = time_of_PRO,
                      integer_time_expansion = FALSE) %>%
  mutate(type = "Pro")
```



```{r fig.cap = "\\label{fig:cifs}Empirical cumulative incidence functions of prodrome (symptom) onset and measles rash appearance.  We see that there is approximately a a constant lag between the two curves."}
plot_df <- bind_rows(cif_rash, cif_prodromes)

ggplot(data = plot_df,
       aes(x = t, y = X1, col = type)) + 
  geom_step() + 
  labs(title = "Cumulative incidence of measles appearance",
       x = "Time (days relative to first prodrome appearance)",
       y = "Cumulative incidence of event") + 
  coord_cartesian(xlim = c(0, 55)) +
  scale_color_manual(values = c("blue", "red"))

```


```{r echo = FALSE, results = 'hide'}
data(hagelloch_raw)
with(hagelloch_raw, sum(PRO > ERU, na.rm = TRUE))

```

The real power of \code{agents_to_aggregate()} lies in its ability to aggregate over any number of pre-specified states.  For example, the Hagelloch data sets contains two columns, \code{tI} and \code{tR}, the time of infection and recovery, respectively of each individual.  We can then plot the SIR values through a time-invariant lens using \pkg{ggplot2} and \pkg{ggtern} functions (as shown in Fig. \ref{fig:hag-tern-raw}) or with our custom \code{geom}, \code{geom_aggregate}, which takes the raw agent data as input.

```{r fig.cap = "\\label{fig:hag-tern-raw}Time invariant view of the Hagelloch epidemic where we view the individuals in Susceptible, Infectious, or Recovered states.  We see there are two peaks of infection (the vertical axis)."}
hagelloch_sir <- hagelloch_raw %>%
  agents_to_aggregate(states = c(tI, tR),
                      min_max_time = c(0, 55)) %>%
  rename(time = t, S = X0, I = X1, R = X2)


ggplot(hagelloch_sir, aes(x = S, y = I, z = R))+
  coord_tern() +
  geom_path() +
  labs(x = "S", y = "I", z = "R",
       title = "Time invariant view of Hagelloch measles outbreak") + 
  theme_sir(base_size = 24)

```

Moreover, we can look at the outbreaks of the disease by group within \code{agent_to_aggregate()} or \code{geom_aggregate()}.  This allows us to examine differences among the different groups of individuals.  For example, we show the time invariant outbreak by class level in Figure \ref{fig:tern-class-data}.  Immediately, we see that time invariant infection curve is different for the pre-school class compared to the 1st class.  In the 1st class, we see about 95\% of the class become infected and less than 10\% of them having recovered, which is indicative of a super-spreading event.  This suspicion is further confirmed in that `r max(table(hagelloch_raw$IFTO[hagelloch_raw$CL == "1st class"]))` of the `r nrow(hagelloch_raw[hagelloch_raw$CL == "1st class",])` 1st class students have been reportedly infected by the same individual.

```{r fig.cap = "\\label{fig:tern-class-data}Time invariant outbreak curves for the three class groups.  The pre-school class has a distinct peak of infection whereas the peak infection point for the other two classes are less well defined."}
hagelloch_raw %>%
  ggplot(aes(y = tI, z = tR, color = CL)) +
  geom_aggregate(size = 2) + coord_tern() +
  labs(x = "S", y = "I", z = "R",
       color = "Class") +
  scale_color_brewer(palette = "Dark2") +
  facet_wrap(~CL)
```

Along with multiple epidemic states, the function \code{agents_to_aggregate} can also be extended to populations with vital dynamics (e.g. birth and death) and examples of this are shown in the package vignette.  In summary, \code{agents_to_aggregate()} is a multi-purpose workhorse that may be leveraged to convert individual level records into aggregate information that may be more useful for some forms of epidemic modeling such as compartment modeling.

Up to this point, we have used \pkg{EpiCompare} in the context of observed data.  We also want to compare statistical models, and \pkg{EpiCompare} aids in that process via a simple but dynamic individual-level data generator, conversion tools for popular epidemic model packages, and model assessments.  We demonstrate an example here.

We first try to model the Hagelloch data with a stochastic SIR model, which we refer to as the 'simple SIR.'  In our vignette, we show how to fit this simple SIR model via maximum likelihood and simulate from the model with those best fit parameters.  Our function \code{simulate_agents()} generates individual level data according to discrete time multinomial draws, which depend on the number of individuals in each state at the previous time step and a matrix of transition probabilities.  For example, the below code generates 100 simulations of an outbreak of a disease with one initial infector in a population of $n= 188$ individuals.


```{r}
trans_mat <- matrix(c("X0 * (1 - X1 * par1 / N)", "X0 * X1  * par1 / N", "0",
                  "0", "X1 * (1 - par2)", "par2 * X1",
                  "0", "0", "X2"), byrow = TRUE, nrow = 3)
```



```{r cache = TRUE}
set.seed(2020)

best_params <- c("beta" = .36, "gamma" = .13)
## This is the SIR representation

rownames(trans_mat) <- c("S", "I", "R")
init_vals <- c(187, 1, 0)
par_vals <- c(par1 = best_params[1], par2 = best_params[2])
max_T <- 55
n_sims <- 100

agents <- simulate_agents(trans_mat,
                       init_vals,
                       par_vals,
                       max_T,
                       n_sims,
                       verbose = FALSE)


```
```{r}
agg_model <- agents %>% group_by(sim) %>%
  agents_to_aggregate(states = c(I, R)) %>%
  mutate(Type = "Simple SIR")
```
The result of our simulation is the object \code{agents} which is a `r nrow(agents)` $\times$ `r ncol(agents)` data frame, which details the time of entry into the $S$, $I$, and $R$ states for a given simulation.  Before we examine the results of this simple SIR model, we will also examine another, more sophisticated SIR model, this time from the package \pkg{EpiModel}.  Briefly, this model first fits a contact network to the set of indivduals, where the class of the student is a covariate.  The model then simulates a SIR-epidemic on that network.

```{r cache = TRUE, results = 'hide'}
library(EpiModel)
## WARNING:  Will take a minute or two

set.seed(42)
nw <- network.initialize(n = 188, directed = FALSE)
nw <- set.vertex.attribute(nw, "group", rep(0:2, each = 90, 30, 68))
formation <- ~edges + nodematch("group") + concurrent
target.stats <- c(200, 300, 200)
coef.diss <- dissolution_coefs(dissolution = ~offset(edges),  duration = 5)
est1 <- netest(nw, formation, target.stats, coef.diss, edapprox = TRUE)

param <- param.net(inf.prob = 0.1, act.rate = 5, rec.rate = 0.1)
status.vector <- c(rep(0, 90), rep(0, 30), rep(0, 67), 1)
status.vector <- ifelse(status.vector == 1, "i", "s")
init <- init.net(status.vector = status.vector)
control <- control.net(type = "SIR", nsteps = 55,
                       nsims = 100, epi.by = "group")
epimodel_sir <- netsim(est1, param, init, control)

```


The output of this model is \code{epimodel_sir}, an object of class \code{`r class(epimodel_sir)`}, which contains a plethora of modeling information.  We provide the function \code{fortify_aggregate()}, which can take objects from specialized classes of modeling output and transform it into a tidy-style data frame.

```{r}
fortified_net <- fortify_aggregate(epimodel_sir, 
                                   states = c("s.num", "i.num", "r.num")) %>%
  mutate(Type = "EpiModel SIR",
         sim = as.numeric(gsub("sim", "", sim)))
```


We can then analyze the results of the two models side by side as time-invariant epidemic curves.  The results are shown in Figure \ref{fig:hag-simple-sir}, where a 90\% prediction band is estimated from the delta ball method for each of the two models.  For the Simple SIR model, we see that the data generally covers the data fairly well but clearly misses the second peak of infection.  We also see that the prediction band is very large, covering up a large area of the ternary plot.  On the other hand, for the \pkg{EpiModel} model, we see that the prediction band covers the data quite well and takes up less area.



```{r cache = TRUE}

both_models <- bind_rows(agg_model, fortified_net)


g <- ggplot() + geom_prediction_band(data = both_models %>% filter(t != 0),
         aes(x = X0, y = X1, z = X2,
              sim_group = sim, fill = Type),
         alpha = .5,
         conf_level = .90) 
```

```{r , fig.cap = "\\label{fig:hag-simple-sir}  Original Hagelloch SIR data (black) along with 90\\% prediction band and actual simulation paths from the Simple SIR and the EpiModel SIR models."}
g +   geom_path(data = both_models %>% filter(t !=0),
            aes(x = X0, y = X1, z = X2, group = paste(Type, sim)),
            alpha = .3, col = "gray40") + 
    coord_tern() + theme_sir(base_size = 24) +
  geom_point(data = hagelloch_sir,
             aes(x = S, y = I, z =R), col = "black") +
  labs(title = "Simple SIR model",
       subtitle = "90% Prediction band and original data",
       x = "S", y = "I", z = "R") +
  scale_fill_manual(values = c("#006677", "#AA6600")) + 
  facet_wrap(~Type) +
  theme(legend.position = "bottom")
     
```

However, both models are not a good fit to the filamental path as opposed to the individual points in $(S, I, R)$-space.  This can be captures with the set of simulations both models predict, which all generally have a single defined peak of infection whereas the data certainly looks like it has two distinct peaks, likely caused by our assumed super-spreader event.  This observation is backed up by the below analysis that demonstrates that the estimated psuedo-density of the observed epidemic (relative to the simulations from either model) is much less likely then **any** of the simulations (reported in Table \ref{tab:hags-extreme}. In conclusion, \pkg{EpiCompare} makes it clear that, at a glance, 1) the EpiModel network model is a better fit than the Simple SIR model, and 2) the fit is only good at the individual point level as opposed to the epidemic path level.


```{r echo = F}
simple_sir <- both_models %>% filter(Type == "Simple SIR") %>%
  rename(S = "X0", I = "X1", R = "X2") %>%
  select(Type, sim, t, S, I, R)

hagelloch_sir2 <- hagelloch_sir %>%
  rename(t = "time") %>%
  mutate(Type = "true observation",
         sim = 0) %>%
  select(Type, sim, t, S, I, R)
```
```{r}
#-- after cleaning up and combining --
all_together_df <- rbind(simple_sir,
                         hagelloch_sir2)
```

```{r echo = F}
all_together_df[c(1:2, nrow(all_together_df) - c(1:0)),] %>% 
  kable(booktabs = TRUE,
        caption = paste("Top and bottom 2 rows of \\tt{all\\_together\\_df}\\text{,",
                        "combining both simulated epidemics and the true",
                        "epidemic.}"), label = "cif-all-together-df") %>%
  kable_styling(position = "center", 
                latex_options = "hold_position"
                      )
```

```{r}
compression_df <- all_together_df %>% group_by(Type, sim) %>% 
  filament_compression(data_columns = c("S","I","R"), 
                       number_points = 20)
```

```{r echo = F}
# # -OR- for 2d onto the simplex (done under the hood in geom_prediction_band:
# compression_df <- all_together_df %>% 
#   as.data.frame() %>% # just to be sure...
#   get_xy_coord(xyz_col = c("S", "I", "R")) %>% # to 2d simplex space
#   group_by(Type, sim) %>%
#   filament_compression(data_columns = c("x","y"), 
#                        number_points = 20)

```

```{r}
tdmat <- compression_df %>% 
  dist_matrix_innersq_direction(
    position = c(1:length(compression_df))[
      names(compression_df) %in% c("S","I", "R")],
    tdm_out = T)

simple_sir_true_obs_info <- tdmat %>% 
  compare_new_to_rest_via_distance(
    new_name_id = data.frame(Type = "true observation", sim = 0),
    distance_func = distance_psuedo_density_function, 
    sigma = "20%") 

```

```{r echo = F}
# EpiModel simulations:
epimodel_sir <- both_models %>% filter(Type == "EpiModel SIR") %>%
  rename(S = "X0", I = "X1", R = "X2") %>%
  select(Type, sim, t, S, I, R)

hagelloch_sir2 <- hagelloch_sir %>%
  rename(t = "time") %>%
  mutate(Type = "true observation",
         sim = 0) %>%
  select(Type, sim, t, S, I, R)

all_together_df <- rbind(epimodel_sir,
                         hagelloch_sir2)

compression_df <- all_together_df %>% group_by(Type, sim) %>% 
  filament_compression(data_columns = c("S","I","R"), 
                       number_points = 20)

tdmat <- compression_df %>% 
  dist_matrix_innersq_direction(
    position = c(1:length(compression_df))[
      names(compression_df) %in% c("S","I", "R")],
    tdm_out = T)

epimodel_sir_true_obs_info <- tdmat %>% 
  compare_new_to_rest_via_distance(
    new_name_id = data.frame(Type = "true observation", sim = 0),
    distance_func = distance_psuedo_density_function, 
    sigma = "20%") 
```

```{r hagelloch-extremeness, echo = FALSE}
simple_sir_info <- simple_sir_true_obs_info %>%
  select(-sim) %>%
  mutate(Type = "Simple SIR")
eimodel_sir_info <- epimodel_sir_true_obs_info %>%
  select(-sim) %>%
  mutate(Type = "EpiModel SIR")

rbind(simple_sir_info, eimodel_sir_info)  %>%
  kable(format = "latex", booktabs = TRUE, 
        col.names = 
          linebreak(c("Type",
                      "simulations-based estimated psuedo-density",
              "proportion of simulations with lower estimated psuedo-density"),
              align = c("l")),
        caption = paste("The extremeness of the true simulations based on",
                        "comparing psuedo-density estimates between true",
                        "vs simulated curves"), label = "hags-extreme") %>%
  kable_styling(position = "center", latex_options = "hold_position") %>%
  column_spec(2:3, width = "6cm")
```



# A. Appendix {-}

## A.1 Proof of Theorem \ref{thm:sir-scale} {-}

\begin{proof}\label{proof:thm}
\cite{Harko2014} provide an analytical solution for the Kermack and McKendrick equations (Eq. \eqref{eq:sir-ode}) by reparameterizing the ODEs so that $\mathcal{S}(u) = S(t)$, $\mathcal{I}(u) = S(t)$, and $\mathcal{R}(u) = R(t)$ for $0< u_T < 1$ with
\begin{align}\label{eq:harko-odes}
\mathcal{S}(u) &= S(0)u\\
\mathcal{I}(u) &= N - R(0) + NR_0^{-1}\log u - S(0)u \nonumber\\
\mathcal{R}(u) &= R(0) - NR_0^{-1} \log u, \nonumber
\end{align}
and $u$ and t are related by the following integral,
\begin{align*}
    t &= \int_{u}^1 \frac{N}{\beta \tau (N - R(0) + R_{0}^{-1} \log \tau - S(0)\tau)}d\tau \\
    &= \int_{u}^1 \frac{1}{\beta f(S(0), R(0), N, R_0, \tau)} d \tau\\
    &= \int_{u}^1 \frac{1}{\beta f(\tau)} d\tau,
\end{align*}
where we have made the denominator of the integral a function of $N$, the initial values, $R_0$, and $\tau$, which we further condense to $f(\tau)$ for brevity.
Then for a given $t$ we want to find $s$ such that $(S_1(t), I_1(t), R_1(t)) = (S_2(s), I_2(s), R_2(s))$.  Or equivalently, for a fixed $u$ want to find $v$ such that  $\mathcal{S}_1(u) = \mathcal{S}_2(v)$ and then the corresponding $t$ and $s$ are given by
\begin{align*}
    t & = \int_{u}^1 \frac{1}{\beta_1 f(\tau)} d\tau \\
    s & = \int_{v}^1 \frac{1}{\beta_2 f(\tau)} d\tau.
\end{align*}
Note that since the equations in Eq. \eqref{eq:harko-odes} are functions of the initial values and $R_0$, then $u = v$. We then can find a relation for $s$,
    \begin{align*}
    s & = \int_{u}^1 \frac{1}{\beta_2 f(\tau)} d\tau  \\
    & = \int_{u}^1 \frac{1}{a\beta_1 f(\tau)} d\tau \\ 
    &= \frac{1}{a}\int_{u}^1 \frac{1}{\beta_1 f(\tau)} d\tau \\
    &= \frac{1}{a}t.
\end{align*}
\end{proof}



